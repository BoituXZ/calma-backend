# Training Pipeline Summary

## ğŸ¯ What Was Done

Your Calma AI model was overfitting. I've created a complete retraining pipeline with anti-overfitting measures using a large, diverse Hugging Face dataset.

## ğŸ“¦ New Files Created

### Core Training Scripts
1. **`train_with_hf_dataset.py`** - Complete training pipeline (main entry point)
2. **`src/data_processing_hf.py`** - HuggingFace dataset processor with quality filtering
3. **`src/model_training_improved.py`** - Training with anti-overfitting measures

### Setup & Testing
4. **`setup_training.sh`** - One-command environment setup
5. **`test_setup.py`** - Verify installation and configuration
6. **`requirements-training.txt`** - Python dependencies

### Documentation
7. **`QUICKSTART.md`** - Quick start guide (recommended read!)
8. **`RETRAINING_GUIDE.md`** - Comprehensive training documentation
9. **`TRAINING_SUMMARY.md`** - This file

## ğŸ”§ Anti-Overfitting Measures Implemented

### Dataset Level
- âœ… Using large, diverse HF dataset (10,000+ conversations vs 248KB)
- âœ… Proper train/validation/test splits (80/10/10)
- âœ… Quality filtering (removes repetitive, low-quality examples)
- âœ… Dynamic padding (no padding during tokenization)
- âœ… Removed aggressive data augmentation

### Model Level
- âœ… Early stopping (stops when validation loss stops improving)
- âœ… Increased LoRA dropout (0.15 vs 0.1)
- âœ… Weight decay / L2 regularization (0.01)
- âœ… Lower learning rate (1e-4 vs 2e-4)
- âœ… Stronger gradient clipping (1.0 vs 0.3)
- âœ… Rank-stabilized LoRA (`use_rslora=True`)
- âœ… Frequent validation checks for early stopping

### Training Process
- âœ… Separate validation and test sets
- âœ… Saves only best 3 checkpoints
- âœ… Monitors validation vs test loss difference
- âœ… Automatic warnings if overfitting detected

## ğŸš€ How to Use

### Quick Start (3 commands)
```bash
./setup_training.sh              # Setup environment
huggingface-cli login            # Login (first time only)
python3 train_with_hf_dataset.py # Start training
```

### Test First (Recommended)
```bash
./setup_training.sh
huggingface-cli login
python3 train_with_hf_dataset.py --max-samples 100 --epochs 1
```

### Full Documentation
See [QUICKSTART.md](QUICKSTART.md) for detailed instructions.

## ğŸ“Š Expected Results

### Before (Overfitting)
```
Training Loss: 0.3
Validation Loss: 2.5
Test Loss: 2.8
â†’ Large gap indicates overfitting
```

### After (Good Generalization)
```
Training Loss: 1.2
Validation Loss: 1.3
Test Loss: 1.3
â†’ Small gap (< 0.1) indicates good generalization
```

## ğŸ¯ Key Improvements

| Aspect | Old | New |
|--------|-----|-----|
| Dataset | 248KB (~300 examples) | 10,000+ conversations |
| Splits | Train/Test (80/20) | Train/Val/Test (80/10/10) |
| Augmentation | Aggressive (1.3x) | Minimal, quality-focused |
| Dropout | 0.1 | 0.15 |
| Early Stopping | âŒ | âœ… |
| Weight Decay | 0.001 | 0.01 |
| Learning Rate | 2e-4 | 1e-4 |
| Quality Filtering | âŒ | âœ… |

## ğŸ“ Directory Structure After Training

```
calma-ai/
â”œâ”€â”€ train_with_hf_dataset.py          â† Run this!
â”œâ”€â”€ setup_training.sh                 â† Setup script
â”œâ”€â”€ test_setup.py                     â† Test setup
â”œâ”€â”€ QUICKSTART.md                     â† Quick start guide
â”œâ”€â”€ RETRAINING_GUIDE.md              â† Detailed guide
â”œâ”€â”€ requirements-training.txt         â† Dependencies
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_processing_hf.py        â† HF dataset processor
â”‚   â”œâ”€â”€ model_training_improved.py   â† Training script
â”‚   â””â”€â”€ ...
â”œâ”€â”€ data/
â”‚   â””â”€â”€ processed/
â”‚       â””â”€â”€ hf_mental_health_dataset/ â† Processed data
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ calma-final/                 â† Old model (backup this!)
â”‚   â””â”€â”€ calma-hf-trained/            â† New trained model
â”‚       â””â”€â”€ final/                   â† Use this!
â””â”€â”€ calma/                           â† Virtual environment
```

## âš™ï¸ Configuration Options

All options for `train_with_hf_dataset.py`:

```bash
--max-samples N               # Limit dataset size (for testing)
--epochs N                    # Training epochs (default: 3)
--learning-rate FLOAT         # Learning rate (default: 1e-4)
--weight-decay FLOAT          # L2 regularization (default: 0.01)
--lora-dropout FLOAT          # LoRA dropout (default: 0.15)
--early-stopping-patience N   # Stop after N evals without improvement
--skip-data-prep             # Use existing processed dataset
--output-dir PATH            # Model output directory
```

## ğŸ” How to Know If It Worked

### During Training
Watch for:
- Validation loss decreasing smoothly
- Small gap between training and validation loss
- Early stopping trigger (means it converged)

### After Training
Check the metrics:
```
Loss Difference: 0.05 â†’ âœ… Excellent (< 0.1)
Loss Difference: 0.15 â†’ âš ï¸  Fair (0.1-0.2)
Loss Difference: 0.35 â†’ âŒ Still overfitting (> 0.2)
```

### In Production
Test with real conversations:
- More natural responses
- Better handling of diverse topics
- Doesn't repeat memorized phrases

## ğŸ”„ Integration with Two-Model System

Your system uses two models (from [TWO_MODEL_SYSTEM.md](../TWO_MODEL_SYSTEM.md)):

1. **Casual Model** - Base Llama (unchanged)
2. **Therapeutic Model** - Your fine-tuned model (â† update this)

After training:
```bash
# Backup old model
cp -r models/calma-final models/calma-final-backup

# Use new model
cp -r models/calma-hf-trained/final/* models/calma-final/

# Restart backend
cd ..
npm run start:dev
```

## ğŸ› Troubleshooting

### Setup Issues
Run: `python3 test_setup.py`

### Authentication Issues
```bash
huggingface-cli login
```

### Memory Issues
- Reduce samples: `--max-samples 5000`
- Lower batch size: Edit `model_training_improved.py` line 102

### Still Overfitting
Progressive approach:
```bash
python3 train_with_hf_dataset.py --max-samples 1000  # Start small
python3 train_with_hf_dataset.py --max-samples 5000  # Increase
python3 train_with_hf_dataset.py                     # Full dataset
```

## ğŸ“š Dataset Information

**Source**: [`Amod/mental_health_counseling_conversations`](https://huggingface.co/datasets/Amod/mental_health_counseling_conversations)

**Content**: Professional mental health counseling conversations
**Size**: ~10,000+ conversations
**Quality**: High (professional counselor responses)
**License**: Check dataset page on Hugging Face

## ğŸ“ Technical Details

### Why This Fixes Overfitting

1. **More diverse data** â†’ Model learns patterns, not examples
2. **Quality filtering** â†’ Removes noise that causes overfitting
3. **Early stopping** â†’ Stops before memorization begins
4. **Regularization** â†’ Penalizes complex models
5. **Proper validation** â†’ Detects overfitting during training
6. **Dynamic padding** â†’ Doesn't learn padding patterns

### LoRA Configuration
```python
r=16                    # Rank
lora_alpha=32           # Scaling
lora_dropout=0.15       # Dropout (increased)
use_rslora=True         # Rank-stabilized (new)
target_modules=[        # All attention + MLP
    "q_proj", "v_proj", "k_proj", "o_proj",
    "gate_proj", "up_proj", "down_proj"
]
```

### Training Configuration
```python
learning_rate=1e-4              # Lower for stability
weight_decay=0.01               # L2 regularization
max_grad_norm=1.0               # Gradient clipping
lr_scheduler_type="cosine"      # Smooth decay
early_stopping_patience=3       # Stop after 3 no-improve
```

## âœ… Checklist

Before training:
- [ ] Virtual environment activated
- [ ] Dependencies installed (`setup_training.sh`)
- [ ] Hugging Face login (`huggingface-cli login`)
- [ ] Test passed (`python3 test_setup.py`)
- [ ] Backed up old model

After training:
- [ ] Validation-test loss difference < 0.1
- [ ] Tested with evaluation script
- [ ] Integrated with backend
- [ ] Tested in production
- [ ] Monitored real-world performance

## ğŸ‰ Next Steps

1. **Setup**: Run `./setup_training.sh`
2. **Login**: `huggingface-cli login`
3. **Test**: `python3 train_with_hf_dataset.py --max-samples 100 --epochs 1`
4. **Train**: `python3 train_with_hf_dataset.py`
5. **Evaluate**: Check loss difference
6. **Deploy**: Update model in production
7. **Monitor**: Watch real-world performance

## ğŸ“– Additional Resources

- [QUICKSTART.md](QUICKSTART.md) - Quick start guide
- [RETRAINING_GUIDE.md](RETRAINING_GUIDE.md) - Detailed documentation
- [TWO_MODEL_SYSTEM.md](../TWO_MODEL_SYSTEM.md) - Model architecture
- [CLAUDE.md](CLAUDE.md) - Project overview

---

**Questions?** Check the documentation or run `python3 test_setup.py` to verify setup.

**Ready to train?** Start with [QUICKSTART.md](QUICKSTART.md)! ğŸš€
